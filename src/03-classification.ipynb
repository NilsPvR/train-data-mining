{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c41a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load cleaned data from preprocessing step\n",
    "journeys = pd.read_csv('../data/train-drives-cleaned.csv', encoding='utf-8')\n",
    "\n",
    "# Select only relevant columns\n",
    "journeys_filtered = journeys.loc[:, journeys.columns.str.startswith('train_line') | journeys.columns.isin(['planned_departure_hour', 'day_of_week'])]\n",
    "class_label_df = journeys['crowdedness']\n",
    "\n",
    "# Split into train and test sets\n",
    "journeys_train, journeys_test, class_label_train, class_label_test = train_test_split(journeys_filtered, class_label_df, test_size=0.2, random_state=123)\n",
    "journeys_filtered.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa89379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# == Plot the crowdedness by planned departure time ==\n",
    "\n",
    "# Group by hour and crowdedness, count occurrences\n",
    "journeys_visual = journeys.groupby(['planned_departure_hour', 'crowdedness']).size().reset_index(name='count')\n",
    "\n",
    "# Normalize the counts per hour\n",
    "journeys_visual['normalized_count'] = journeys_visual.groupby('planned_departure_hour')['count'].transform(lambda x: x / x.sum())\n",
    "\n",
    "plt.figure(figsize=(7, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.barplot(data=journeys_visual, x='planned_departure_hour', y='normalized_count', hue='crowdedness', palette='viridis')\n",
    "plt.title('Normalized crowdedness by planned departure hour')\n",
    "plt.xlabel('Planned departure hour')\n",
    "plt.ylabel('Normalized number of journeys')\n",
    "plt.legend(title='Crowdedness', loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# == Plot the total number of journeys by planned departure time ==\n",
    "journeys_total = journeys.groupby('planned_departure_hour').size().reset_index(name='total_count')\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.barplot(data=journeys_total, x='planned_departure_hour', y='total_count')\n",
    "plt.title('Total number of train journeys by planned departure hour')\n",
    "plt.xlabel('Planned departure hour')\n",
    "plt.ylabel('Number of journeys')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b12778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "## Create decision tree with gini index\n",
    "class_labels = class_label_df.unique().astype(str)\n",
    "decision_tree_model = DecisionTreeClassifier(criterion='gini', random_state=123)\n",
    "decision_tree_model.fit(journeys_train, class_label_train)\n",
    "\n",
    "# Plot resulting tree\n",
    "plt.figure(figsize=(40, 20))\n",
    "plot_tree(decision_tree_model, filled=True, feature_names=journeys_train.columns, class_names=class_labels, rounded=False)\n",
    "plt.title('Decision tree classifier (gini index)')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate model\n",
    "predictions = decision_tree_model.predict(journeys_test)\n",
    "accuracy = accuracy_score(class_label_test, predictions)\n",
    "print(f'Accuracy of gini index decision tree: {accuracy:.2f}')\n",
    "print(classification_report(class_label_test, predictions, target_names=class_labels, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67850835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Possible parameters for hyperparameter tuning\n",
    "# We want to limit the size of the tree to avoid overfitting\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "# Search for best parameters and train model\n",
    "grid_search = GridSearchCV(estimator=decision_tree_model,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=3,               # 5-fold cross-validation\n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1)          # Use all CPU cores\n",
    "grid_search.fit(journeys_train, class_label_train)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Plot resulting tree\n",
    "plt.figure(figsize=(40, 20))\n",
    "plot_tree(grid_search.best_estimator_, filled=True, feature_names=journeys_train.columns, class_names=class_labels, rounded=True)\n",
    "plt.title('Decision tree classifier (accuracy)')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate model\n",
    "predictions = grid_search.best_estimator_.predict(journeys_test)\n",
    "accuracy = accuracy_score(class_label_test, predictions)\n",
    "print(f'Accuracy of gini index decision tree: {accuracy:.2f}')\n",
    "print(classification_report(class_label_test, predictions, target_names=class_labels, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c09ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the planned departure and day of week to make them comparable\n",
    "cols_to_scale = ['planned_departure_hour', 'day_of_week']\n",
    "journeys_train_scaled = journeys_train.copy()\n",
    "journeys_test_scaled = journeys_test.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "journeys_train_scaled[cols_to_scale] = scaler.fit_transform(journeys_train[cols_to_scale])\n",
    "journeys_test_scaled[cols_to_scale] = scaler.transform(journeys_test[cols_to_scale])\n",
    "\n",
    "\n",
    "# Use SMOTE to generate synthetic samples for minority class\n",
    "smote = SMOTE(random_state=123, k_neighbors=3)\n",
    "journeys_train_balanced, class_label_train_balanced = smote.fit_resample(journeys_train_scaled, class_label_train)\n",
    "\n",
    "# Use cross-validation to find best k\n",
    "k_range = range(1, 21)\n",
    "cv_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn_classifier, journeys_train_balanced, class_label_train_balanced, cv=3, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "\n",
    "best_k = k_range[cv_scores.index(max(cv_scores))]\n",
    "print(f'Best k found by cross-validation: {best_k}')\n",
    "\n",
    "# Train model again with bset k\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_classifier.fit(journeys_train_balanced, class_label_train_balanced)\n",
    "\n",
    "# Evaluate the KNN model\n",
    "knn_predictions = knn_classifier.predict(journeys_test_scaled)\n",
    "knn_accuracy = accuracy_score(class_label_test, knn_predictions)\n",
    "print(f'Accuracy of KNN Classifier: {knn_accuracy:.3f}')\n",
    "print(classification_report(class_label_test, knn_predictions, target_names=class_labels, zero_division=0))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
